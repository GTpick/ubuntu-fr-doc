===== Webalizer =====

<note tip>Webalizer est un logiciel permettant d'analyser l'utilisation des serveurs web en générant, à partir de leurs journaux d'accès (log), des comptes rendus sous forme de pages web. Diffusé sous licence GPL, c'est aujourd'hui un des outils d'administration de serveur web les plus utilisés (2005), en particulier sur les architectures LAMP.</note>
<note tip>Webalizer peut être installé depuis les paquets. L'article suivant présente une installation depuis les sources.</note>


Le tutoriel ci dessous vous explique comment installer webalizer sur une machine dotée du proxy squid


**Depuis Webmin**

Webalizer nécessite un dossier, à indiquer dans Webmin, dans lequel il enregistrera les rapports générés. Créez donc un dossier ''webalizer'' dans le dossier personnel :

  mkdir ~/webalizer

Puis installez le depuis la console webmin

**Depuis les sources**

Il est fortement conseillé d'installer la dernière version de Webalizer, disponible sur le site des créateurs. Attention ce n'est pas la même version que celle proposée sur webmin.

pour cela téléchargeons d'abord les sources:

  wget ftp://ftp.mrunix.net/pub/webalizer/webalizer-2.21-02-src.tgz

ensuite décompressons l'archive:

  tar -zxvf webalizer-2.21-02-src.tgz

Vous obtenez alors le répertoire webalizer-2.21-02
On y accède:

  cd webalizer-2.21-02

A ce stade, il est nécessaire d'installer des logiciels tiers afin de correctement compiler l'application;

<note important>Si les sources que je cite plus bas ne suffisent pas à correctement compiler webalizer, pensez à regarder le message d'erreur obtenu afin de savoir quoi installer, par exemple **checking for main in -lz... no
configure: error: z library not found.. please install libz
** vous indique que la librairie libz doit être installée avant de compiler.</note>

  sudo apt-get install zlib1g-dev
  sudo apt-get install libpng12-dev
  sudo apt-get install libgd2-noxpm-dev

Une fois ceci fait, on compile

  ./configure --with-language=french
  make
  sudo make install

L'opération terminée, vous trouverez un exemple de configuration dans **/usr/local/etc/webalizer.conf.sample**

Copions le afin d'avoir l'original sous la main en cas de problème

  cd /usr/local/etc/
  
  sudo cp webalizer.conf.sample webalizer.conf
 
Puis éditons le afin de le modifier

  sudo nano webalizer.conf

Voici les lignes à décommenter/modifier

  LogFile        /var/log/squid/access.log
  OutputDir      /var/www/webalizer ## apache doit être installé! ##
  HistoryName     webalizer.hist
  Incremental     yes
  IncrementalName webalizer.current
  ReportTitle    Statistiques Webalizer ##mettez ce que vous souhaitez voir apparaitre sur votre rapport##
  HostName        NomDuProxy
  PageType        htm*
  PageType        cgi
  HTAccess        yes ##si vous souhaitez gérer un accès par mot de passe aux statistiques de Webalizer.##
  LinkReferrer    yes ## lien html directement accessible depuis la page web##
  TopSites        20
  TopKSites       20
  TopURLs         20
  TopKURLs        20
  TopReferrers    20
  TopAgents       20
  TopCountries    20
  TopEntry        20
  TopExit         10
  TopSearch       20
  TopUsers        20
  ideSite        *votredomaine.com
  HideSite        votredomaine.com
  HideSite        localhost
  HideReferrer    votredomaine.com
  HideReferrer    Direct Request ## les 5 lignes ci dessus afin de ne pas prendre en compte les accès locaux sur Squid ##
  HideURL         *.gif
  HideURL         *.GIF
  HideURL         *.jpg
  HideURL         *.JPG
  HideURL         *.png
  HideURL         *.PNG
  HideURL         *.ra
  IgnoreSite      localhost
  IgnoreURL       /taskbar*
  SearchEngine.yahoo.com.p=
  SearchEngine.altavista.com.q=
  SearchEngine.google.com.q=
  SearchEngine.google.fr.q=
  SearchEngine.google.be.q=
  SearchEngine.google.ca.q=
  SearchEngine.google.co.ma.q=
  SearchEngine.google.co.uk.q=
  SearchEngine.eureka.com.q=
  SearchEngine.google.ch.q=
  SearchEngine.lycos.com.query=
  SearchEngine.hotbot.com.MT=
  SearchEngine.search.live.com.q=
  SearchEngine.search.msn.com.q=
  SearchEngine.infoseek.com.qt=
  SearchEngine.webcrawler.searchText=
  SearchEngine.excite..search=
  SearchEngine.netscape.com.search=
  SearchEngine.mamma.com.query=
  SearchEngine.alltheweb.com.query=
  SearchEngine.northernlight.com.qr=

<note important>De nombreuses options sont disponibles pour personnaliser le résultat, n'hésitez pas à regarde le fichier de conf principal</note>

Nous avons enfin notre fichier de configuration prêt, avec dans mon exemple les résultats qui s'enregistreront dans /var/www/webalizer/

Nous pouvons lancer la commande:

  sudo webalizer

  Webalizer V2.21-02 (Linux 2.6.24-19-server i686) French
  Using logfile /var/log/squid/access.log (clf)
  Creating output in /var/www/webalizer
  Hostname for reports is 'MonProxy'
  Reading history file... webalizer.hist
  Reading previous run data... webalizer.current
  Saving current run data... [03/18/2009 13:51:06]
  Generating report for Mars 2009
  Saving history information...
  Generating summary report
  7293 records (3378 ignored) in 1 seconds, 7293/sec

Vous n'obtiendrez pas forcément le même résultat que l'exemple ci dessus, car la première fois webalizer indique qu'il n'a pas trouvé de fichiers plus anciens, ce qui est logique...

Vérifions que le rapport à bien été généré 

  cd /var/www/webalyser
  ls -l

Qui me donne:

  -rw-r--r-- 1 root root   2186 2009-03-17 15:48 ctry_usage_200903.png
  -rw-r--r-- 1 root root   2823 2009-03-18 13:52 daily_usage_200903.png
  -rw-r--r-- 1 root root   2076 2009-03-18 13:52 hourly_usage_200903.png
  -rw-r--r-- 1 root root   3762 2009-03-18 13:52 index.html
  -rw-r--r-- 1 root root 108635 2009-03-18 13:52 usage_200903.html
  -rw-r--r-- 1 root root   2201 2009-03-18 13:52 usage.png
  -rw-r--r-- 1 root root 579914 2009-03-18 13:52 webalizer.current
  -rw-r--r-- 1 root root   2880 2009-03-18 13:52 webalizer.hist

Accédons y depuis un navigateur web

  http://ipdemonproxy/webalizer/index.htm

Vous obtiendrez normalement cette magnifique page:

{{:tutoriel:webalizer.jpg|}}

Libre à vous ensuite de faire vos recherches selon le mois sélectionné.


**Générer un script pour lancer webalizer tous les jours**

Afin d'automatiser la tâche, il est nécessaire de rajouter un script.

  cd /etc/cron.daily/

Puis créez un script:
 
  sudo nano 0logrotate-webalizer

Entrez ensuite les paramètres suivants;


  #!/bin/sh
  sudo webalizer
  /usr/sbin/logrotate /etc/logrotate.conf


Le script se lancera donc tous les jours, et exécutera webalizer.

//Auteur : [[:utilisateurs:geronimoO]].//